1.개념
 - 페이지에서 제거할 때 가장 오랫동안 사용하지 않은 것을 제거하겠다는 알고리즘
 - 기본적으로 오랫동안 사용하지 않은 데이터라면 앞으로도 사용할 확률이 적다는 가정
 
2. LRU(Least Recently Used) 캐시 교체 알고리즘
 - 캐시에서 메모리를 다루기 위해 사용되는 알고리즘
 - 캐시가 사용할 수 있는 리소스는 한정되어 있고 이 공간 내에서 데이터를 빠르게 저장/접근 해야함
 - 메모리 상에서 가장 최근에 사용된 적이 없는 캐시의 메모리부터 대체하며 새로운 데이터를 갱신
   * 캐시?
    - 자주 사용하는 데이터나 값을 미리 복사해 놓은 임시 장소
    - 저장 공간이 작고 비용이 비싼 대신 빠른 성공 제공 [레지스터 -> 캐시 -> 메인메모리 -> SSD/HDD]
    - 원래 데이터에 접근하는 시간이 오래 걸리는 경우, 반복적으로 동일한 결과를 return 하는 경우
    - DB, Server의 부하를 줄이고 성능을 높이기 위해 사용
    - 원하는 데이터가 캐시에 존재하는 경우 : 해당 데이터 반환 == Cache Hit
    - 원하는 데이터가 캐시에 존재하지 않은 경우 : DB 또는 서버에 요청 == Cache Miss
    - 캐시는 저장공간이 적기 때문에 지속적으로 Cache Miss가 발생하는 경우 캐시 전략에 따라 저장중인 데이터를 변경해야함!
   * Long Tail == 파레토법칙
    - 20%의 요구가 시스템 리소스의 대부분을 사용 -> 얘내들을 Cache를 이용해야 리소스 사용량을 줄이고 성능 대폭 향상 가능
   * Local Cache Vs Global Cache
   [Local Cache]
    - Local 장비 내에서만 사용되는 Cache로 Local 장비의 Resource를 이용
    - Local에서만 작동하기 때문에 속도가 빠르지만 다른 서버와의 데이터 공유가 어렵다.
   [Global Cache]
    - 여러 서버에서 Cache Server에 접근하여 사용. 분산된 서버에서 데이터를 저장하고 조회할 수 있다.
    - 네트워크를 통해 데이터를 가져오므로 상대적으로 느리지만 별도의 Cache 서버를 이용하기 때문에 서버 간 데이터 공유가 쉽다.
   * Mapping (사상)
    - 가상주소와 물리주소의 대응 관계 // 가상 주소로부터 물리 주소를 찾는 일
    - 캐시 메모리와 메인 메모리의 주소 체계가 다르기 때문
